# FlashVSR Architecture Diagram

## ðŸ—ï¸ **FlashVSR Model Architecture**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                              FlashVSR Pipeline                                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                                 â”‚
â”‚  Input Video (LQ) â”€â”€â”                                                          â”‚
â”‚                     â”‚                                                          â”‚
â”‚                     â–¼                                                          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚                    Three-Stage Distillation Pipeline                    â”‚   â”‚
â”‚  â”‚                                                                         â”‚   â”‚
â”‚  â”‚  Stage 1: LQ Projection (Buffer_LQ4x_Proj)                             â”‚   â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚   â”‚
â”‚  â”‚  â”‚  Input: (B, 3, F, H, W) â†’ Output: Multi-scale LQ latents        â”‚   â”‚   â”‚
â”‚  â”‚  â”‚  â€¢ 3D Convolution layers                                         â”‚   â”‚   â”‚
â”‚  â”‚  â”‚  â€¢ Stream processing (2-7 frames at a time)                     â”‚   â”‚   â”‚
â”‚  â”‚  â”‚  â€¢ Output: [LQ_latents[0], LQ_latents[1], ..., LQ_latents[N]]   â”‚   â”‚   â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚   â”‚
â”‚  â”‚                                                                         â”‚   â”‚
â”‚  â”‚  Stage 2: Diffusion Transformer (WanModel)                             â”‚   â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚   â”‚
â”‚  â”‚  â”‚  â€¢ Locality-Constrained Sparse Attention (LCSA)                 â”‚   â”‚   â”‚
â”‚  â”‚  â”‚  â€¢ Block-Sparse Attention with dynamic masking                  â”‚   â”‚   â”‚
â”‚  â”‚  â”‚  â€¢ RoPE (Rotary Position Embedding)                            â”‚   â”‚   â”‚
â”‚  â”‚  â”‚  â€¢ KV Cache for streaming efficiency                           â”‚   â”‚   â”‚
â”‚  â”‚  â”‚  â€¢ 30 transformer blocks                                       â”‚   â”‚   â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚   â”‚
â”‚  â”‚                                                                         â”‚   â”‚
â”‚  â”‚  Stage 3: Tiny Conditional Decoder (TCDecoder)                         â”‚   â”‚   â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚   â”‚
â”‚  â”‚  â”‚  â€¢ Multi-scale channels: [512, 256, 128, 128]                  â”‚   â”‚   â”‚
â”‚  â”‚  â”‚  â€¢ Latent channels: 16 + 768 = 784                             â”‚   â”‚   â”‚
â”‚  â”‚  â”‚  â€¢ Efficient reconstruction without VAE                         â”‚   â”‚   â”‚
â”‚  â”‚  â”‚  â€¢ Parallel processing capability                               â”‚   â”‚   â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                                                 â”‚
â”‚                     â–¼                                                          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚                    Color Correction (Optional)                          â”‚   â”‚   â”‚
â”‚  â”‚  â€¢ Wavelet-based color matching                                        â”‚   â”‚   â”‚
â”‚  â”‚  â€¢ ADAIN (Adaptive Instance Normalization)                             â”‚   â”‚   â”‚
â”‚  â”‚  â€¢ Chunked processing for memory efficiency                            â”‚   â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                                                 â”‚
â”‚                     â–¼                                                          â”‚
â”‚  Output Video (HQ) â”€â”€â”˜                                                         â”‚
â”‚                                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ðŸ”§ **Key Components Breakdown**

### **1. LQ Projection (Buffer_LQ4x_Proj)**
```
Input: (B, 3, F, H, W)  â†’  Output: Multi-scale LQ latents
â”œâ”€â”€ 3D Convolution layers
â”œâ”€â”€ Stream processing (2-7 frames chunks)
â”œâ”€â”€ Output: [LQ_latents[0], LQ_latents[1], ..., LQ_latents[N]]
â””â”€â”€ Memory: ~2-4GB VRAM per frame
```

### **2. Diffusion Transformer (WanModel)**
```
Architecture: 30 transformer blocks
â”œâ”€â”€ Locality-Constrained Sparse Attention (LCSA)
â”‚   â”œâ”€â”€ Block-Sparse Attention with dynamic masking
â”‚   â”œâ”€â”€ Top-k selection for efficiency
â”‚   â””â”€â”€ Local range: 9-11 (configurable)
â”œâ”€â”€ RoPE (Rotary Position Embedding)
â”‚   â”œâ”€â”€ 3D positional encoding (time, height, width)
â”‚   â””â”€â”€ Streaming-friendly design
â”œâ”€â”€ KV Cache System
â”‚   â”œâ”€â”€ pre_cache_k, pre_cache_v for streaming
â”‚   â”œâ”€â”€ Memory-efficient attention
â”‚   â””â”€â”€ Bridge train-test resolution gap
â””â”€â”€ Memory: ~8-16GB VRAM (depends on resolution)
```

### **3. Tiny Conditional Decoder (TCDecoder)**
```
Multi-scale Architecture:
â”œâ”€â”€ Channels: [512, 256, 128, 128]
â”œâ”€â”€ Latent channels: 16 + 768 = 784
â”œâ”€â”€ Efficient reconstruction (no VAE needed)
â”œâ”€â”€ Parallel processing capability
â””â”€â”€ Memory: ~4-8GB VRAM
```

## ðŸš€ **FlashVSR vs FlashVSR-Tiny Comparison**

| Component | FlashVSR (Full) | FlashVSR-Tiny | Memory Savings |
|-----------|-----------------|---------------|----------------|
| **DiT Model** | 14B parameters | 1.3B parameters | ~10x smaller |
| **VAE** | Full VAE decoder | TCDecoder only | ~5x smaller |
| **Attention** | Dense + Sparse | Sparse only | ~3x faster |
| **Total VRAM** | 24-40GB | 8-16GB | ~2-3x less |
| **Speed** | ~17 FPS | ~25-30 FPS | ~1.5x faster |

## ðŸ“Š **Memory Requirements by Resolution**

| Resolution | Full Model | Tiny Model | Vidaio Compatible |
|------------|------------|------------|-------------------|
| **480pâ†’1080p** | 16-24GB | 6-10GB | âœ… **YES** |
| **1080pâ†’4K** | 24-32GB | 8-12GB | âœ… **YES** |
| **480pâ†’4K** | 20-28GB | 8-12GB | âœ… **YES** |
| **4Kâ†’8K** | 32-40GB | 12-16GB | âœ… **YES** |

## âš¡ **Streaming Processing Flow**

```
1. Input Video (5-10 seconds, 150-300 frames)
   â†“
2. Frame Chunking (2-7 frames per chunk)
   â†“
3. LQ Projection (per chunk)
   â†“
4. Diffusion Transformer (streaming with KV cache)
   â†“
5. TCDecoder (efficient reconstruction)
   â†“
6. Color Correction (optional)
   â†“
7. Output Video (full duration maintained)
```

## ðŸŽ¯ **Vidaio Subnet Compatibility**

**FlashVSR-Tiny is PERFECT for Vidaio subnet**:

âœ… **Memory**: 8-16GB VRAM (fits A100-40GB easily)  
âœ… **Speed**: 25-30 FPS (faster than RealESRGAN)  
âœ… **Quality**: State-of-the-art diffusion-based upscaling  
âœ… **Duration**: Handles full 5-10 second videos  
âœ… **Resolution**: Supports all Vidaio task types  

**FlashVSR-Tiny > RealESRGAN for Vidaio mining!**


